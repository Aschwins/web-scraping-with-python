{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Building Scrapers\n",
    "\n",
    "## Your first Web Scraper\n",
    "\n",
    "For Johnny and Sep: http://www.wefeelfine.org/wefeelfine_mac.html\n",
    "\n",
    "For codes and examples by the girl herself: https://github.com/REMitchell/python-scraping\n",
    "\n",
    "What will be done?\n",
    "• Retrieving HTML data from a domain name\n",
    "• Parsing that data for target information\n",
    "• Storing the target information\n",
    "• Optionally, moving to another page to repeat the process\n",
    "\n",
    "Let's take some web pages apart.\n",
    "\n",
    "### Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\") \n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen # https://docs.python.org/3/library/urllib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Introduction to BeautifulSoup\n",
    "“Beautiful Soup, so rich and green,  \n",
    "Waiting in a hot tureen!  \n",
    "Who for such dainties would not stoop?  \n",
    "Soup of the evening, beautiful Soup!”  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x1051ef438>\n"
     ]
    }
   ],
   "source": [
    "html2 = urlopen(\"http://www.thuisbezorgd.nl\")\n",
    "print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\") \n",
    "bsObj = BeautifulSoup(html.read(), 'html5lib')\n",
    "print(bsObj.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Reliably\n",
    "A lot can go wrong while scraping the web. So it's wise to take in to account the things that can go wrong.\n",
    "* The page is not found on the server\n",
    "* The server is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    # return null, break, or do some other \"Plan B\"\n",
    "else:\n",
    "    # program continues. Note: If you return or break in the \n",
    "    # exception catch, you do not need to use the \"else\" statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if html is None:\n",
    "    print(\"URL is not found\")\n",
    "else:\n",
    "    # Program continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs0bj.nonExistentTag)\n",
    "\n",
    "print(bs0bj.nonExistentTag.someTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    badContent = bs0bj.nonExistingTag.anotherTag\n",
    "except AttributeError as e:\n",
    "    print(\"Tag was not found\")\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print(\"Tag was not found\")\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
